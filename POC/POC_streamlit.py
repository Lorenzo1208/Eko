import streamlit as st
import pandas as pd
import numpy as np
import pydeck as pdk
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from prophet import Prophet
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# Configuration de la page Streamlit
st.set_page_config(
    page_title="Eko - Surveillance des RiviÃ¨res d'Occitanie",
    page_icon="ğŸ’§",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Fonction pour charger les donnÃ©es des mesures hydromÃ©triques
@st.cache_data
def load_hydro_data(file_path="mesures_hydro_occitanie_2020_2025_20250520_100820.csv"):
    try:
        # VÃ©rifier si le fichier existe dans le rÃ©pertoire POC
        import os
        if not os.path.exists(file_path) and os.path.exists(f"POC/{file_path}"):
            file_path = f"POC/{file_path}"
        
        st.write(f"Tentative de chargement du fichier : {file_path}")
        
        # Chargement du fichier CSV avec des options plus robustes
        df = pd.read_csv(file_path, 
                         encoding='utf-8', 
                         low_memory=False, 
                         on_bad_lines='skip')
        
        # VÃ©rifier que les colonnes attendues existent
        date_column = None
        if 'date_obs_elab' in df.columns:
            date_column = 'date_obs_elab'
        elif 'date_obs' in df.columns:
            date_column = 'date_obs'
        else:
            st.warning("Aucune colonne de date trouvÃ©e. VÃ©rifiez le format du fichier.")
            # CrÃ©er une colonne date par dÃ©faut
            df['date'] = pd.Timestamp('2025-01-01')
            return df
        
        # Convertir les dates en datetime avec gestion des erreurs
        df['date'] = pd.to_datetime(df[date_column], errors='coerce')
        
        # Supprimer les lignes avec des dates invalides
        invalid_dates = df['date'].isna().sum()
        if invalid_dates > 0:
            st.warning(f"{invalid_dates} lignes avec des dates invalides ont Ã©tÃ© trouvÃ©es et seront ignorÃ©es.")
            df = df.dropna(subset=['date'])
        
        # Extraire des informations temporelles supplÃ©mentaires
        df['year'] = df['date'].dt.year
        df['month'] = df['date'].dt.month
        df['day'] = df['date'].dt.day
        df['day_of_year'] = df['date'].dt.dayofyear
        
        # Assurez-vous que la colonne 'code_station_id' existe
        if 'code_station_id' not in df.columns and 'code_entite' in df.columns:
            df['code_station_id'] = df['code_entite']
        
        # Assurez-vous que la colonne 'nom_station' existe
        if 'nom_station' not in df.columns and 'libelle_station' in df.columns:
            df['nom_station'] = df['libelle_station']
        
        # VÃ©rifier que les colonnes essentielles existent
        flow_column = 'resultat_obs_elab' if 'resultat_obs_elab' in df.columns else 'resultat_obs'
        if flow_column not in df.columns:
            st.error(f"Colonne de dÃ©bit '{flow_column}' non trouvÃ©e dans le fichier.")
            # CrÃ©er une colonne factice pour Ã©viter les erreurs
            df[flow_column] = 10.0  # Valeur par dÃ©faut
        
        st.success(f"Fichier chargÃ© avec succÃ¨s : {len(df)} lignes de donnÃ©es.")
        return df
    
    except FileNotFoundError:
        st.error(f"Fichier non trouvÃ© : {file_path}")
        st.info("Veuillez uploader votre fichier CSV de donnÃ©es hydromÃ©triques.")
        return None
    except pd.errors.EmptyDataError:
        st.error(f"Le fichier {file_path} est vide.")
        return None
    except pd.errors.ParserError:
        st.error(f"Erreur lors de l'analyse du fichier {file_path}. Format CSV incorrect.")
        return None
    except Exception as e:
        import traceback
        st.error(f"Erreur lors du chargement des donnÃ©es: {str(e)}")
        st.code(traceback.format_exc())
        return None

# Fonction pour crÃ©er un DataFrame des stations uniques avec leurs coordonnÃ©es
@st.cache_data
def extract_stations_info(data_df):
    if data_df is None:
        return None
    
    try:
        # SÃ©lectionner les colonnes pertinentes et supprimer les doublons
        station_cols = ['code_station_id', 'nom_station', 'longitude', 'latitude']
        
        # VÃ©rifier si toutes les colonnes existent
        if not all(col in data_df.columns for col in station_cols):
            # Pour les colonnes manquantes, crÃ©er des mappings par dÃ©faut
            if 'code_station_id' not in data_df.columns and 'code_station' in data_df.columns:
                data_df['code_station_id'] = data_df['code_station']
                
            # Si des coordonnÃ©es sont manquantes, gÃ©nÃ©rer des coordonnÃ©es fictives centrÃ©es sur l'Occitanie
            if 'longitude' not in data_df.columns:
                data_df['longitude'] = 1.444 + np.random.normal(0, 0.5, len(data_df))
            if 'latitude' not in data_df.columns:
                data_df['latitude'] = 43.6 + np.random.normal(0, 0.3, len(data_df))
        
        # SÃ©lectionner les colonnes disponibles
        available_cols = [col for col in station_cols if col in data_df.columns]
        
        # CrÃ©er le DataFrame des stations
        stations_df = data_df[available_cols].drop_duplicates().reset_index(drop=True)
        
        # Ajouter des informations sur le cours d'eau si disponibles
        if 'libelle_cours_eau' in data_df.columns:
            stations_df = pd.merge(
                stations_df,
                data_df[['code_station_id', 'libelle_cours_eau']].drop_duplicates(),
                on='code_station_id',
                how='left'
            )
        
        return stations_df
    except Exception as e:
        st.error(f"Erreur lors de l'extraction des informations des stations: {str(e)}")
        return None

# Fonction pour calculer les seuils statistiques par station
@st.cache_data
def calculate_thresholds(df):
    if df is None or len(df) == 0:
        return None
        
    try:
        # Identifier la colonne de dÃ©bit
        flow_column = 'resultat_obs_elab' if 'resultat_obs_elab' in df.columns else 'resultat_obs'
        
        # Grouper par station
        grouped = df.groupby('code_station_id')
        
        # Calculer les seuils
        thresholds = grouped.agg(
            debit_min=(flow_column, 'min'),
            debit_max=(flow_column, 'max'),
            debit_moyen=(flow_column, 'mean'),
            seuil_vigilance=(flow_column, lambda x: np.percentile(x, 75)),
            seuil_alerte=(flow_column, lambda x: np.percentile(x, 90)),
            seuil_alerte_renforcee=(flow_column, lambda x: np.percentile(x, 95)),
            seuil_crise=(flow_column, lambda x: np.percentile(x, 98))
        ).reset_index()
        
        return thresholds
    except Exception as e:
        st.error(f"Erreur lors du calcul des seuils: {str(e)}")
        return None

# Fonction pour calculer les seuils mensuels
@st.cache_data
def calculate_monthly_thresholds(df):
    if df is None or len(df) == 0:
        return None
        
    try:
        # Identifier la colonne de dÃ©bit
        flow_column = 'resultat_obs_elab' if 'resultat_obs_elab' in df.columns else 'resultat_obs'
        
        # Grouper par station et mois
        grouped = df.groupby(['code_station_id', 'month'])
        
        # Calculer les seuils
        thresholds = grouped.agg(
            debit_min=(flow_column, 'min'),
            debit_max=(flow_column, 'max'),
            debit_moyen=(flow_column, 'mean'),
            seuil_vigilance=(flow_column, lambda x: np.percentile(x, 75)),
            seuil_alerte=(flow_column, lambda x: np.percentile(x, 90)),
            seuil_alerte_renforcee=(flow_column, lambda x: np.percentile(x, 95)),
            seuil_crise=(flow_column, lambda x: np.percentile(x, 98))
        ).reset_index()
        
        return thresholds
    except Exception as e:
        st.error(f"Erreur lors du calcul des seuils mensuels: {str(e)}")
        return None

# Fonction pour crÃ©er un modÃ¨le de prÃ©diction (RandomForest ou Prophet)
@st.cache_resource
def create_prediction_model(df, station_id, method="randomforest"):
    if df is None or len(df) == 0:
        return None
        
    try:
        # Filtrer les donnÃ©es pour la station sÃ©lectionnÃ©e
        station_data = df[df['code_station_id'] == station_id].copy()  # Ajout de .copy()
        
        # VÃ©rifier s'il y a suffisamment de donnÃ©es
        if len(station_data) < 10:
            st.warning(f"Pas assez de donnÃ©es pour la station {station_id}. Le modÃ¨le peut Ãªtre imprÃ©cis.")
            if len(station_data) < 5:
                return None
        
        # Choisir le bon modÃ¨le en fonction de la mÃ©thode
        if method.lower() == "prophet":
            # PrÃ©parer les donnÃ©es pour Prophet
            flow_column = 'resultat_obs_elab' if 'resultat_obs_elab' in station_data.columns else 'resultat_obs'
            prophet_df = pd.DataFrame({
                'ds': station_data['date'],
                'y': station_data[flow_column]
            })
            
            # CrÃ©er et entraÃ®ner le modÃ¨le
            model = Prophet(daily_seasonality=True)
            model.fit(prophet_df)
            return {"type": "prophet", "model": model}
            
        else:  # RandomForest par dÃ©faut
            # PrÃ©parer les donnÃ©es pour RandomForest
            flow_column = 'resultat_obs_elab' if 'resultat_obs_elab' in station_data.columns else 'resultat_obs'
            
            # CaractÃ©ristiques de base pour le modÃ¨le
            features = ['month', 'day_of_year']
            
            # Ajouter la saison encodÃ©e si disponible
            saison_encoder = None
            if 'saison' in station_data.columns:
                # Encoder la saison
                le = LabelEncoder()
                station_data.loc[:, 'saison_encoded'] = le.fit_transform(station_data['saison'])  # Utilisation de .loc
                features.append('saison_encoded')
                saison_encoder = le
            
            # S'assurer que toutes les features existent
            X = station_data[features].copy()
            y = station_data[flow_column]
            
            # Diviser en ensembles d'entraÃ®nement et de test
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # EntraÃ®ner le modÃ¨le
            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
            rf_model.fit(X_train, y_train)
            
            # Stocker les informations importantes pour les prÃ©dictions
            model_info = {
                "type": "randomforest",
                "model": rf_model,
                "features": features,
                "saison_encoder": saison_encoder,
                "has_saison_feature": 'saison' in station_data.columns
            }
            
            return model_info
            
    except Exception as e:
        st.error(f"Erreur lors de la crÃ©ation du modÃ¨le de prÃ©diction: {str(e)}")
        return None

# Fonction pour faire des prÃ©dictions avec le modÃ¨le
def make_predictions(model_info, df, station_id, days=30):
    if model_info is None:
        return None
        
    try:
        # RÃ©cupÃ©rer les informations de la station
        station_data = df[df['code_station_id'] == station_id]
        
        # DÃ©terminer la derniÃ¨re date disponible
        last_date = station_data['date'].max()
        
        # GÃ©nÃ©rer les dates futures
        future_dates = [last_date + timedelta(days=i) for i in range(1, days + 1)]
        
        # Faire les prÃ©dictions en fonction du type de modÃ¨le
        if model_info["type"] == "prophet":
            # CrÃ©er un DataFrame avec les dates futures pour Prophet
            future = pd.DataFrame({"ds": pd.date_range(start=last_date, periods=days+1)[1:]})
            
            # Faire les prÃ©dictions
            forecast = model_info["model"].predict(future)
            
            # PrÃ©parer le rÃ©sultat
            result = pd.DataFrame({
                "date": forecast["ds"],
                "prediction": forecast["yhat"],
                "lower_bound": forecast["yhat_lower"],
                "upper_bound": forecast["yhat_upper"]
            })
            
        else:  # RandomForest
            # CrÃ©er les caractÃ©ristiques pour les dates futures
            future_features = []
            for date in future_dates:
                features_dict = {
                    "month": date.month,
                    "day_of_year": date.timetuple().tm_yday
                }
                
                # Ajouter la saison si nÃ©cessaire
                if model_info.get("has_saison_feature", False) and model_info.get("saison_encoder") is not None:
                    # DÃ©terminer la saison en fonction du mois
                    if 3 <= date.month <= 5:
                        saison = "Printemps"
                    elif 6 <= date.month <= 8:
                        saison = "Ã‰tÃ©"
                    elif 9 <= date.month <= 11:
                        saison = "Automne"
                    else:
                        saison = "Hiver"
                    
                    features_dict["saison_encoded"] = model_info["saison_encoder"].transform([saison])[0]
                    
                future_features.append(features_dict)
            
            # CrÃ©er un DataFrame avec les caractÃ©ristiques futures
            future_df = pd.DataFrame(future_features)
            
            # S'assurer que toutes les features utilisÃ©es lors de l'entraÃ®nement sont prÃ©sentes
            for feature in model_info["features"]:
                if feature not in future_df.columns:
                    st.warning(f"Feature manquante: {feature}. Le modÃ¨le pourrait Ãªtre imprÃ©cis.")
                    # Si c'est la saison qui manque, on pourrait crÃ©er une colonne factice
                    if feature == 'saison_encoded' and 'month' in future_df.columns:
                        # CrÃ©er une saison encodÃ©e basÃ©e sur le mois
                        future_df['saison_encoded'] = future_df['month'].apply(
                            lambda m: 0 if m in [12, 1, 2] else  # Hiver
                                    1 if m in [3, 4, 5] else     # Printemps
                                    2 if m in [6, 7, 8] else     # Ã‰tÃ©
                                    3                            # Automne
                        )
            
            # Faire les prÃ©dictions en utilisant uniquement les features disponibles dans le modÃ¨le
            available_features = [f for f in model_info["features"] if f in future_df.columns]
            predictions = model_info["model"].predict(future_df[available_features])
            
            # Calculer des intervalles de confiance approximatifs
            std_dev = np.std(predictions) if len(predictions) > 1 else 0
            lower_bounds = predictions - 1.96 * std_dev
            upper_bounds = predictions + 1.96 * std_dev
            
            # PrÃ©parer le rÃ©sultat
            result = pd.DataFrame({
                "date": future_dates,
                "prediction": predictions,
                "lower_bound": lower_bounds,
                "upper_bound": upper_bounds
            })
            
        return result
    except Exception as e:
        st.error(f"Erreur lors de la prÃ©diction: {str(e)}")
        st.exception(e)  # Afficher la trace complÃ¨te pour dÃ©boguer
        return None

# Fonction pour afficher une carte des stations avec PyDeck
def display_station_map(stations_df, thresholds_df):
    if stations_df is None or len(stations_df) == 0:
        st.error("Aucune donnÃ©e de station disponible pour la carte.")
        return None
        
    try:
        # Fusionner les donnÃ©es des stations avec les seuils
        if thresholds_df is not None:
            map_data = pd.merge(
                stations_df, 
                thresholds_df, 
                left_on='code_station_id',
                right_on='code_station_id', 
                how='left'
            )
        else:
            map_data = stations_df.copy()
        
        # Afficher les valeurs numÃ©riques correctement formatÃ©es
        for col in ['debit_moyen', 'seuil_alerte', 'seuil_crise']:
            if col in map_data.columns:
                map_data[f'{col}_fmt'] = map_data[col].apply(lambda x: f"{x:.2f}" if pd.notnull(x) else "N/A")
        
        # CrÃ©er une colonne pour la couleur en fonction du seuil
        def determine_color(row):
            if 'debit_moyen' not in row or pd.isna(row.get('debit_moyen')):
                return [150, 150, 150]  # Gris pour les stations sans donnÃ©es
            
            if 'seuil_crise' in row and not pd.isna(row.get('seuil_crise')):
                if row['debit_moyen'] > row['seuil_crise']:
                    return [255, 0, 0]  # Rouge pour stations au-dessus du seuil de crise
                elif row['debit_moyen'] > row['seuil_alerte']:
                    return [255, 165, 0]  # Orange pour stations au-dessus du seuil d'alerte
                else:
                    return [0, 100, 255]  # Bleu pour stations normales
            else:
                return [0, 100, 255]  # Bleu par dÃ©faut
        
        map_data['color'] = map_data.apply(determine_color, axis=1)
        
        # CrÃ©er la couche des stations - TAILLE RÃ‰DUITE
        stations_layer = pdk.Layer(
            'ScatterplotLayer',
            data=map_data,
            get_position=['longitude', 'latitude'],
            get_color='color',
            get_radius=5000,  # Rayon rÃ©duit Ã  5 km (au lieu de 25 km)
            pickable=True,
            auto_highlight=True,
            opacity=0.8,
        )
        
        # DÃ©finir la vue initiale (centrÃ©e sur l'Occitanie)
        view_state = pdk.ViewState(
            longitude=1.4442,  # CoordonnÃ©es approximatives pour l'Occitanie
            latitude=43.6047,
            zoom=7,
            pitch=0,
        )
        
        # CrÃ©er le tooltip avec les valeurs formatÃ©es
        tooltip = {
            "html": "<b>Station:</b> {nom_station}<br>",
            "style": {"backgroundColor": "steelblue", "color": "white"}
        }
        
        # Ajouter les informations de dÃ©bit si disponibles
        if 'debit_moyen_fmt' in map_data.columns:
            tooltip["html"] += "<b>DÃ©bit moyen:</b> {debit_moyen_fmt} mÂ³/s<br>"
        
        if 'seuil_alerte_fmt' in map_data.columns:
            tooltip["html"] += "<b>Seuil alerte:</b> {seuil_alerte_fmt} mÂ³/s"
        
        # CrÃ©er la carte
        r = pdk.Deck(
            layers=[stations_layer],
            initial_view_state=view_state,
            tooltip=tooltip,
            map_style="light",
        )
        
        return r
    except Exception as e:
        st.error(f"Erreur lors de la crÃ©ation de la carte: {str(e)}")
        return None

def main():
    # Titre de l'application
    st.title("ğŸŒŠ Eko - Surveillance des RiviÃ¨res d'Occitanie")
    
    # Charger les donnÃ©es
    data = load_hydro_data()
    
    # Si aucun fichier par dÃ©faut n'est trouvÃ©, permettre Ã  l'utilisateur d'uploader son propre fichier
    if data is None:
        st.warning("Aucun fichier de donnÃ©es par dÃ©faut trouvÃ©. Veuillez uploader votre CSV de donnÃ©es hydromÃ©triques.")
        uploaded_file = st.file_uploader("Choisissez un fichier CSV", type="csv")
        if uploaded_file is not None:
            data = pd.read_csv(uploaded_file)
            # Convertir les dates et ajouter les colonnes temporelles
            date_column = 'date_obs_elab' if 'date_obs_elab' in data.columns else 'date_obs'
            if date_column in data.columns:
                data['date'] = pd.to_datetime(data[date_column])
                data['year'] = data['date'].dt.year
                data['month'] = data['date'].dt.month
                data['day'] = data['date'].dt.day
                data['day_of_year'] = data['date'].dt.dayofyear
    
    # VÃ©rifier si des donnÃ©es sont disponibles
    if data is None or len(data) == 0:
        st.error("Aucune donnÃ©e disponible. Veuillez vÃ©rifier votre fichier CSV.")
        return
    
    # Extraire les informations des stations
    stations_info = extract_stations_info(data)
    
    # Calcul des seuils
    with st.spinner("Calcul des seuils d'alerte..."):
        thresholds_df = calculate_thresholds(data)
        monthly_thresholds_df = calculate_monthly_thresholds(data)
    
    # Afficher des informations sur les donnÃ©es chargÃ©es
    st.sidebar.subheader("Informations sur les donnÃ©es")
    st.sidebar.info(f"Nombre de stations: {data['code_station_id'].nunique()}")
    st.sidebar.info(f"Nombre total d'observations: {len(data)}")
    
    if 'date' in data.columns:
        st.sidebar.info(f"PÃ©riode des donnÃ©es: du {data['date'].min().strftime('%d/%m/%Y')} au {data['date'].max().strftime('%d/%m/%Y')}")
    
    # Sidebar pour les contrÃ´les
    st.sidebar.title("ContrÃ´les")
    
    # 1. SÃ©lection de la station
    station_options = data[['code_station_id', 'nom_station']].drop_duplicates()
    
    # VÃ©rifier si station_options n'est pas vide
    if len(station_options) > 0:
        selected_station = st.sidebar.selectbox(
            "SÃ©lectionner une station",
            station_options['code_station_id'].tolist(),
            format_func=lambda x: f"{x} - {station_options[station_options['code_station_id'] == x]['nom_station'].values[0]}"
        )
    else:
        st.error("Aucune station disponible. VÃ©rifiez le format de vos donnÃ©es.")
        return
    
    # 2. Type d'affichage
    display_type = st.sidebar.radio(
    "Type d'affichage",
    ["Carte des stations", "Historique des dÃ©bits", "Seuils d'alerte", "PrÃ©dictions", "MÃ©thodologie"])
    
    # 3. Options pour les prÃ©dictions
    if display_type == "PrÃ©dictions":
        prediction_days = st.sidebar.slider(
            "Nombre de jours de prÃ©diction",
            min_value=7,
            max_value=90,
            value=30,
            step=1
        )
        
        prediction_method = st.sidebar.radio(
            "MÃ©thode de prÃ©diction",
            ["RandomForest", "Prophet"],
            help="RandomForest est gÃ©nÃ©ralement plus prÃ©cis pour ce type de donnÃ©es. Prophet est meilleur pour les tendances saisonniÃ¨res."
        )
    else:
        prediction_days = 30  # Valeur par dÃ©faut
        prediction_method = "RandomForest"  # MÃ©thode par dÃ©faut
    
    # Affichage principal en fonction du type sÃ©lectionnÃ©
    if display_type == "Carte des stations":
        st.header("Carte des stations hydromÃ©triques")
        
        # Colonne d'information
        st.markdown("""
        **LÃ©gende**:
        - ğŸ”µ Bleu: Station avec dÃ©bit normal
        - ğŸŸ  Orange: Station au-dessus du seuil d'alerte
        - ğŸ”´ Rouge: Station au-dessus du seuil de crise
        - âšª Gris: Station sans donnÃ©es de dÃ©bit
        """)
        
        # Afficher la carte
        map_chart = display_station_map(stations_info, thresholds_df)
        if map_chart:
            st.pydeck_chart(map_chart)
        
        # Informations supplÃ©mentaires
        st.subheader("Informations sur les stations")
        
        # SÃ©lectionner les colonnes pertinentes pour l'affichage
        display_columns = ['code_station_id', 'nom_station', 'longitude', 'latitude']
        
        if stations_info is not None:
            st.dataframe(stations_info[display_columns])
    
    elif display_type == "Historique des dÃ©bits":
        st.header(f"Historique des dÃ©bits pour la station {selected_station}")
        
        # Filtrer les donnÃ©es pour la station sÃ©lectionnÃ©e
        flow_column = 'resultat_obs_elab' if 'resultat_obs_elab' in data.columns else 'resultat_obs'
        station_data = data[data['code_station_id'] == selected_station].copy()
        station_data = station_data.sort_values('date')
        
        # VÃ©rifier si des donnÃ©es sont disponibles pour cette station
        if len(station_data) == 0:
            st.warning(f"Aucune donnÃ©e de dÃ©bit disponible pour la station {selected_station}.")
            return
        
        # Obtenir les informations de la station
        station_name = station_options[station_options['code_station_id'] == selected_station]['nom_station'].iloc[0]
        st.subheader(f"Station: {station_name}")
        
        # CrÃ©er un graphique des dÃ©bits avec Plotly
        fig = px.scatter(
            station_data,
            x='date',
            y=flow_column,
            title=f"DÃ©bits (mÂ³/s) - Station {selected_station}",
            labels={flow_column: "DÃ©bit (mÂ³/s)", 'date': 'Date'},
            template="plotly_white"
        )
        
        # Ajouter une ligne de tendance
        fig.add_traces(
            px.line(station_data, x='date', y=flow_column).data[0]
        )
        
        # Ajouter les seuils d'alerte s'ils existent
        if thresholds_df is not None:
            threshold_data = thresholds_df[thresholds_df['code_station_id'] == selected_station]
            
            if len(threshold_data) > 0:
                threshold_data = threshold_data.iloc[0]
                fig.add_hline(y=threshold_data['seuil_vigilance'], line_dash="dash", line_color="yellow", annotation_text="Vigilance")
                fig.add_hline(y=threshold_data['seuil_alerte'], line_dash="dash", line_color="orange", annotation_text="Alerte")
                fig.add_hline(y=threshold_data['seuil_alerte_renforcee'], line_dash="dash", line_color="orangered", annotation_text="Alerte renforcÃ©e")
                fig.add_hline(y=threshold_data['seuil_crise'], line_dash="dash", line_color="red", annotation_text="Crise")
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Statistiques des dÃ©bits
        st.subheader("Statistiques des dÃ©bits")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("DÃ©bit minimum", f"{station_data[flow_column].min():.2f} mÂ³/s")
        col2.metric("DÃ©bit moyen", f"{station_data[flow_column].mean():.2f} mÂ³/s")
        col3.metric("DÃ©bit maximum", f"{station_data[flow_column].max():.2f} mÂ³/s")
        col4.metric("Ã‰cart-type", f"{station_data[flow_column].std():.2f} mÂ³/s")
        
        # RÃ©partition saisonniÃ¨re
        if 'saison' in station_data.columns:
            st.subheader("RÃ©partition saisonniÃ¨re")
            
            # Statistiques par saison
            seasonal_stats = station_data.groupby('saison')[flow_column].agg(['mean', 'min', 'max']).reset_index()
            
            # Ordonner les saisons correctement
            season_order = ['Hiver', 'Printemps', 'Ã‰tÃ©', 'Automne']
            seasonal_stats['saison'] = pd.Categorical(seasonal_stats['saison'], categories=season_order, ordered=True)
            seasonal_stats = seasonal_stats.sort_values('saison')
            
            # CrÃ©er un graphique des dÃ©bits par saison
            fig_season = px.bar(
                seasonal_stats,
                x='saison',
                y='mean',
                title="DÃ©bit moyen par saison",
                labels={'mean': "DÃ©bit moyen (mÂ³/s)", 'saison': 'Saison'},
                text_auto='.2f',
                color='saison',
                color_discrete_map={
                    'Hiver': 'royalblue',
                    'Printemps': 'mediumseagreen',
                    'Ã‰tÃ©': 'orange',
                    'Automne': 'brown'
                }
            )
            
            st.plotly_chart(fig_season, use_container_width=True)
    
    elif display_type == "Seuils d'alerte":
        st.header("Seuils d'alerte calculÃ©s")
        
        # 1. Seuils globaux
        st.subheader("Seuils globaux par station")
        if thresholds_df is not None:
            # Joindre les noms des stations pour une meilleure lisibilitÃ©
            display_thresholds = pd.merge(
                thresholds_df,
                station_options,
                on='code_station_id',
                how='left'
            )
            
            # Formater les colonnes numÃ©riques pour un affichage plus lisible
            for col in display_thresholds.columns:
                if col not in ['code_station_id', 'nom_station'] and pd.api.types.is_numeric_dtype(display_thresholds[col]):
                    display_thresholds[col] = display_thresholds[col].round(2)
            
            st.dataframe(display_thresholds)
        else:
            st.warning("Aucun seuil global calculÃ©.")
        
        # 2. Seuils mensuels pour la station sÃ©lectionnÃ©e
        st.subheader(f"Seuils mensuels pour la station {selected_station}")
        
        if monthly_thresholds_df is not None:
            monthly_data = monthly_thresholds_df[monthly_thresholds_df['code_station_id'] == selected_station].copy()
            
            if len(monthly_data) == 0:
                st.warning(f"Aucune donnÃ©e mensuelle disponible pour la station {selected_station}.")
            else:
                # Ajouter les noms des mois
                month_names = {
                    1: 'Janvier', 2: 'FÃ©vrier', 3: 'Mars', 4: 'Avril', 5: 'Mai', 6: 'Juin',
                    7: 'Juillet', 8: 'AoÃ»t', 9: 'Septembre', 10: 'Octobre', 11: 'Novembre', 12: 'DÃ©cembre'
                }
                monthly_data['nom_mois'] = monthly_data['month'].map(month_names)
                
                # Trier par mois
                monthly_data = monthly_data.sort_values('month')
                
                # Formater les valeurs numÃ©riques
                for col in monthly_data.columns:
                    if col not in ['code_station_id', 'month', 'nom_mois'] and pd.api.types.is_numeric_dtype(monthly_data[col]):
                        monthly_data[col] = monthly_data[col].round(2)
                
                # Afficher le tableau des seuils mensuels
                st.dataframe(monthly_data[['nom_mois', 'debit_moyen', 'seuil_vigilance', 'seuil_alerte', 'seuil_alerte_renforcee', 'seuil_crise']])
                
                # Visualisation des seuils mensuels
                fig = px.line(
                    monthly_data, 
                    x='month', 
                    y=['debit_moyen', 'seuil_vigilance', 'seuil_alerte', 'seuil_alerte_renforcee', 'seuil_crise'],
                    title=f"Variation mensuelle des seuils pour la station {selected_station}",
                    labels={'month': 'Mois', 'value': 'DÃ©bit (mÂ³/s)', 'variable': 'Type de seuil'},
                    color_discrete_map={
                        'debit_moyen': 'blue',
                        'seuil_vigilance': 'yellow',
                        'seuil_alerte': 'orange',
                        'seuil_alerte_renforcee': 'orangered',
                        'seuil_crise': 'red'
                    }
                )
                
                # AmÃ©liorer l'axe des x pour afficher les noms des mois
                fig.update_xaxes(
                    tickvals=list(range(1, 13)),
                    ticktext=list(month_names.values())
                )
                
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("Aucun seuil mensuel calculÃ©.")
    
    elif display_type == "PrÃ©dictions":
        st.header(f"PrÃ©dictions de dÃ©bit pour la station {selected_station}")
        
        # Obtenir le nom de la station
        station_name = station_options[station_options['code_station_id'] == selected_station]['nom_station'].iloc[0]
        
        # Filtrer les donnÃ©es pour la station sÃ©lectionnÃ©e
        flow_column = 'resultat_obs_elab' if 'resultat_obs_elab' in data.columns else 'resultat_obs'
        station_data = data[data['code_station_id'] == selected_station].copy()
        
        if len(station_data) < 10:
            st.warning("DonnÃ©es insuffisantes pour faire des prÃ©dictions fiables. Un minimum de 10 points de donnÃ©es est recommandÃ©.")
            if len(station_data) == 0:
                return
        
        # CrÃ©er et entraÃ®ner le modÃ¨le
        with st.spinner("EntraÃ®nement du modÃ¨le de prÃ©diction..."):
            try:
                # DEBUG: Afficher les colonnes disponibles
                st.write("Colonnes disponibles dans le dataset:", data.columns.tolist())
                
                # VÃ©rifier si saison est disponible
                if 'saison' in data.columns:
                    st.write("La colonne 'saison' est disponible et contient:", data['saison'].unique())
                
                model_info = create_prediction_model(data, selected_station, method=prediction_method.lower())
                if model_info is None:
                    st.error("Impossible de crÃ©er le modÃ¨le de prÃ©diction. VÃ©rifiez les donnÃ©es d'entrÃ©e.")
                    return
                
                # DEBUG: Afficher les informations du modÃ¨le
                st.write("Informations du modÃ¨le:", {k: v for k, v in model_info.items() if k != 'model'})
                
                forecast = make_predictions(model_info, data, selected_station, days=prediction_days)
                if forecast is None:
                    st.error("Ã‰chec de la prÃ©diction. VÃ©rifiez le modÃ¨le.")
                    return
            except Exception as e:
                st.error(f"Erreur lors de la crÃ©ation du modÃ¨le de prÃ©diction: {str(e)}")
                st.exception(e)  # Afficher la trace complÃ¨te
                return
        
        # Visualiser les prÃ©dictions
        fig = go.Figure()
        
        # DonnÃ©es historiques
        fig.add_trace(go.Scatter(
            x=station_data['date'],
            y=station_data[flow_column],
            mode='markers',
            name='DonnÃ©es historiques',
            marker=dict(color='blue', size=6)
        ))
        
        # Ajouter une ligne de tendance pour les donnÃ©es historiques
        fig.add_trace(go.Scatter(
            x=station_data['date'],
            y=station_data[flow_column],
            mode='lines',
            name='Tendance historique',
            line=dict(color='royalblue', width=1)
        ))
        
        # PrÃ©dictions
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['prediction'],
            mode='lines',
            name='PrÃ©diction',
            line=dict(color='red', width=2)
        ))
        
        # Intervalle de confiance
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['upper_bound'],
            mode='lines',
            line=dict(width=0),
            showlegend=False
        ))
        
        fig.add_trace(go.Scatter(
            x=forecast['date'],
            y=forecast['lower_bound'],
            mode='lines',
            line=dict(width=0),
            fill='tonexty',
            fillcolor='rgba(255, 0, 0, 0.2)',
            name='Intervalle de confiance'
        ))
        
        # Ajouter les seuils d'alerte s'ils existent
        if thresholds_df is not None:
            threshold_data = thresholds_df[thresholds_df['code_station_id'] == selected_station]
            
            if len(threshold_data) > 0:
                threshold_data = threshold_data.iloc[0]
                fig.add_hline(y=threshold_data['seuil_vigilance'], line_dash="dash", line_color="yellow", annotation_text="Vigilance")
                fig.add_hline(y=threshold_data['seuil_alerte'], line_dash="dash", line_color="orange", annotation_text="Alerte")
                fig.add_hline(y=threshold_data['seuil_crise'], line_dash="dash", line_color="red", annotation_text="Crise")
        
        # Mise en forme du graphique
        fig.update_layout(
            title=f"PrÃ©diction des dÃ©bits pour {station_name}",
            xaxis_title="Date",
            yaxis_title="DÃ©bit (mÂ³/s)",
            hovermode="x unified",
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Informations sur les dÃ©passements de seuil prÃ©vus
        if thresholds_df is not None:
            threshold_data = thresholds_df[thresholds_df['code_station_id'] == selected_station]
            
            if len(threshold_data) > 0:
                threshold_data = threshold_data.iloc[0]
                
                try:
                    # VÃ©rifier s'il y a des dÃ©passements prÃ©vus
                    alert_days = forecast[forecast['prediction'] > threshold_data['seuil_alerte']]
                    crisis_days = forecast[forecast['prediction'] > threshold_data['seuil_crise']]
                    
                    st.subheader("Analyse des risques")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric(
                            "Jours de dÃ©passement du seuil d'alerte prÃ©vus", 
                            len(alert_days),
                            delta=None,
                            delta_color="inverse"
                        )
                        
                        if len(alert_days) > 0:
                            st.write("Dates prÃ©vues de dÃ©passement du seuil d'alerte:")
                            alert_dates = [d.strftime("%d/%m/%Y") for d in alert_days['date']]
                            # Limiter le nombre de dates affichÃ©es si nÃ©cessaire
                            if len(alert_dates) > 10:
                                st.write(", ".join(alert_dates[:10]) + f" et {len(alert_dates) - 10} autres jours")
                            else:
                                st.write(", ".join(alert_dates))
                    
                    with col2:
                        st.metric(
                            "Jours de dÃ©passement du seuil de crise prÃ©vus", 
                            len(crisis_days),
                            delta=None,
                            delta_color="inverse"
                        )
                        
                        if len(crisis_days) > 0:
                            st.write("Dates prÃ©vues de dÃ©passement du seuil de crise:")
                            crisis_dates = [d.strftime("%d/%m/%Y") for d in crisis_days['date']]
                            # Limiter le nombre de dates affichÃ©es si nÃ©cessaire
                            if len(crisis_dates) > 10:
                                st.write(", ".join(crisis_dates[:10]) + f" et {len(crisis_dates) - 10} autres jours")
                            else:
                                st.write(", ".join(crisis_dates))
                except Exception as e:
                    st.error(f"Erreur lors de l'analyse des risques: {str(e)}")
    elif display_type == "MÃ©thodologie":
        st.header("MÃ©thodologie et explications dÃ©taillÃ©es")
        
        # Utilisation des onglets pour organiser les explications
        tab1, tab2, tab3, tab4 = st.tabs(["Sources de donnÃ©es", "Calcul des seuils", "ModÃ¨les de prÃ©diction", "Limites et perspectives"])
        
        with tab1:
            st.subheader("Sources et collecte des donnÃ©es")
            st.markdown("""
            ### Origine des donnÃ©es
            
            Les donnÃ©es hydromÃ©triques utilisÃ©es dans cette application proviennent de l'**API Hub'Eau** (HydromÃ©trie) qui centralise 
            les mesures des stations de surveillance des cours d'eau franÃ§ais.
            
            ### Processus de collecte
            
            1. **SÃ©lection des stations** : L'application utilise les donnÃ©es de stations hydromÃ©triques situÃ©es en rÃ©gion Occitanie.
            - Nombre total de stations surveillÃ©es : {stations_count}
            - PÃ©riode couverte : {period_start} Ã  {period_end}
            
            2. **Types de donnÃ©es collectÃ©es** :
            - **DÃ©bits journaliers** (QmnJ) : Valeurs moyennes journaliÃ¨res des dÃ©bits en mÂ³/s
            - **Hauteurs d'eau** (HmnJ) : Mesures des niveaux d'eau en mÃ¨tres
            
            3. **Volume de donnÃ©es** :
            - Nombre total d'observations : {total_obs}
            - RÃ©partition temporelle : Les donnÃ©es sont rÃ©parties sur plusieurs saisons pour assurer une bonne reprÃ©sentativitÃ©
            """.format(
                stations_count=data['code_station_id'].nunique(),
                period_start=data['date'].min().strftime('%d/%m/%Y'),
                period_end=data['date'].max().strftime('%d/%m/%Y'),
                total_obs=len(data)
            ))
            
            # Ajouter un graphique montrant la rÃ©partition des donnÃ©es
            if 'saison' in data.columns:
                season_counts = data['saison'].value_counts().reset_index()
                season_counts.columns = ['Saison', 'Nombre d\'observations']
                
                # CrÃ©er un ordre personnalisÃ© pour les saisons
                season_order = ['Hiver', 'Printemps', 'Ã‰tÃ©', 'Automne']
                season_counts['Saison'] = pd.Categorical(season_counts['Saison'], categories=season_order, ordered=True)
                season_counts = season_counts.sort_values('Saison')
                
                fig = px.bar(
                    season_counts,
                    x='Saison',
                    y='Nombre d\'observations',
                    title="RÃ©partition des observations par saison",
                    color='Saison',
                    color_discrete_map={
                        'Hiver': 'royalblue',
                        'Printemps': 'mediumseagreen',
                        'Ã‰tÃ©': 'orange',
                        'Automne': 'brown'
                    }
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            st.subheader("Calcul des seuils d'alerte")
            st.markdown("""
            ### MÃ©thodologie de calcul des seuils
            
            Les seuils d'alerte sont calculÃ©s Ã  partir des statistiques historiques des dÃ©bits pour chaque station. L'application 
            utilise une approche basÃ©e sur les percentiles de la distribution des dÃ©bits observÃ©s.
            
            **Seuils calculÃ©s** :
            
            1. **Seuil de vigilance** (75Ã¨me percentile)
            - ReprÃ©sente le niveau au-delÃ  duquel une attention particuliÃ¨re est recommandÃ©e
            - Formule : 75% des observations historiques sont infÃ©rieures Ã  ce seuil
            
            2. **Seuil d'alerte** (90Ã¨me percentile)
            - Indique un niveau Ã©levÃ© nÃ©cessitant une surveillance accrue
            - Formule : 90% des observations historiques sont infÃ©rieures Ã  ce seuil
            
            3. **Seuil d'alerte renforcÃ©e** (95Ã¨me percentile)
            - Signale un niveau trÃ¨s Ã©levÃ© pouvant conduire Ã  des restrictions
            - Formule : 95% des observations historiques sont infÃ©rieures Ã  ce seuil
            
            4. **Seuil de crise** (98Ã¨me percentile)
            - Indique un niveau critique requÃ©rant des mesures d'urgence
            - Formule : 98% des observations historiques sont infÃ©rieures Ã  ce seuil
            
            ### Seuils mensuels
            
            L'application calcule Ã©galement des seuils spÃ©cifiques pour chaque mois de l'annÃ©e, permettant de prendre en compte 
            les variations saisonniÃ¨res des dÃ©bits. Cette approche permet une plus grande prÃ©cision dans la dÃ©tection des anomalies.
            
            **Note importante** : Ces seuils sont calculÃ©s Ã  titre indicatif Ã  partir des donnÃ©es historiques et ne remplacent pas 
            les seuils rÃ©glementaires officiels dÃ©finis par les autoritÃ©s compÃ©tentes.
            """)
            
            # Illustration du calcul des percentiles
            st.image("https://miro.medium.com/max/1200/1*2c21SkzJMf3frPXPAR_gZA.png", 
                    caption="Illustration de la notion de percentile sur une distribution statistique")
        
        with tab3:
            st.subheader("ModÃ¨les de prÃ©diction")
            st.markdown("""
            ### MÃ©thodes de prÃ©diction utilisÃ©es
            
            L'application propose deux approches diffÃ©rentes pour la prÃ©diction des dÃ©bits futurs :
            
            #### 1. Random Forest (ForÃªt alÃ©atoire)
            
            Un modÃ¨le d'apprentissage automatique basÃ© sur un ensemble d'arbres de dÃ©cision.
            
            **CaractÃ©ristiques** :
            - Utilise les variables : mois, jour de l'annÃ©e, saison
            - Nombre d'arbres : 100
            - Validation croisÃ©e : SÃ©paration 80% entraÃ®nement / 20% test
            
            **Avantages** :
            - Capture les relations non-linÃ©aires
            - Robuste face aux valeurs aberrantes
            - Performant avec peu de donnÃ©es
            
            #### 2. Prophet (dÃ©veloppÃ© par Facebook)
            
            Un modÃ¨le de sÃ©rie temporelle conÃ§u pour capturer les tendances et saisonnalitÃ©s.
            
            **CaractÃ©ristiques** :
            - DÃ©compose la sÃ©rie en tendance, saisonnalitÃ© et composante rÃ©siduelle
            - IntÃ¨gre des facteurs de saisonnalitÃ© quotidienne
            
            **Avantages** :
            - Capture efficacement les tendances et cycles saisonniers
            - GÃ¨re bien les donnÃ©es manquantes
            - Fournit des intervalles de confiance
            
            ### Intervalles de confiance
            
            Les prÃ©dictions sont accompagnÃ©es d'intervalles de confiance pour indiquer le niveau d'incertitude.
            
            - Pour **Random Forest** : Intervalle calculÃ© Ã  partir de l'Ã©cart-type (Â± 1.96Ïƒ)
            - Pour **Prophet** : Intervalles de prÃ©diction natifs
            """)
            
            # Diagramme illustrant le processus de prÃ©diction
            st.markdown("""
            ### Processus de prÃ©diction
            
            ```
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  DonnÃ©es       â”‚     â”‚  EntraÃ®nement  â”‚     â”‚  GÃ©nÃ©ration    â”‚
            â”‚  historiques   â”‚â”€â”€â”€â”€>â”‚  du modÃ¨le     â”‚â”€â”€â”€â”€>â”‚  de prÃ©dictions â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                      â”‚                      â”‚
                    â”‚                      â”‚                      â”‚
                    â–¼                      â–¼                      â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Extraction    â”‚     â”‚  Validation    â”‚     â”‚  Analyse des   â”‚
            â”‚  des variables â”‚     â”‚  croisÃ©e       â”‚     â”‚  risques       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            ```
            """)
        
        with tab4:
            st.subheader("Limites et perspectives d'amÃ©lioration")
            st.markdown("""
            ### Limites actuelles
            
            **Limites des donnÃ©es** :
            - Certaines stations disposent de peu d'observations
            - DonnÃ©es parfois discontinues dans le temps
            - Absence de certaines variables contextuelles (prÃ©cipitations, tempÃ©rature)
            
            **Limites des modÃ¨les** :
            - PrÃ©dictions Ã  plus de 30 jours peuvent manquer de fiabilitÃ©
            - DifficultÃ© Ã  prÃ©voir des Ã©vÃ©nements extrÃªmes
            - ModÃ¨les non calibrÃ©s pour les crues exceptionnelles
            
            ### Perspectives d'amÃ©lioration
            
            **Enrichissement des donnÃ©es** :
            - IntÃ©gration de donnÃ©es mÃ©tÃ©orologiques (prÃ©cipitations, tempÃ©ratures)
            - Ajout de caractÃ©ristiques gÃ©ographiques des bassins versants
            - Collecte de donnÃ©es historiques plus complÃ¨tes
            
            **AmÃ©liorations techniques** :
            - DÃ©veloppement de modÃ¨les hybrides combinant diffÃ©rentes approches
            - Utilisation de techniques d'apprentissage profond pour les sÃ©ries temporelles
            - IntÃ©gration d'algorithmes de dÃ©tection d'anomalies plus sophistiquÃ©s
            
            **Ã‰volutions fonctionnelles** :
            - SystÃ¨me d'alerte par email ou SMS
            - Interface mobile optimisÃ©e
            - IntÃ©gration avec d'autres sources de donnÃ©es environnementales
            """)
            
            # Ajouter une citation ou rÃ©fÃ©rence
            st.info("""
            **Pour en savoir plus** : Cette application s'inspire des mÃ©thodes utilisÃ©es par le Service Central 
            d'HydromÃ©tÃ©orologie et d'Appui Ã  la PrÃ©vision des Inondations (SCHAPI) et les Services de PrÃ©vision des Crues (SPC).
            """)
    
    # Pied de page
    st.markdown("---")
    st.markdown("### Ã€ propos")
    st.markdown("""
    Cette application permet de visualiser et d'analyser les donnÃ©es des stations hydromÃ©triques d'Occitanie. 
    Elle calcule des seuils d'alerte basÃ©s sur les statistiques historiques et propose un modÃ¨le de prÃ©diction des dÃ©bits.
    
    **Note:** Les seuils calculÃ©s sont basÃ©s uniquement sur l'analyse statistique des donnÃ©es historiques et ne remplacent pas les seuils rÃ©glementaires officiels.
    """)

if __name__ == "__main__":
    main()
